{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1326 samples, validate on 442 samples\n",
      "Epoch 1/10\n",
      "1326/1326 [==============================] - 28s 21ms/sample - loss: 41.9324 - accuracy: 0.5686 - val_loss: 19.3632 - val_accuracy: 0.0679\n",
      "Epoch 2/10\n",
      "1326/1326 [==============================] - 27s 20ms/sample - loss: 8.8897 - accuracy: 0.7624 - val_loss: 6.8924 - val_accuracy: 0.0724\n",
      "Epoch 3/10\n",
      "1326/1326 [==============================] - 26s 20ms/sample - loss: 3.0240 - accuracy: 0.8062 - val_loss: 6.0244 - val_accuracy: 0.0566\n",
      "Epoch 4/10\n",
      "1326/1326 [==============================] - 29s 22ms/sample - loss: 1.8281 - accuracy: 0.8386 - val_loss: 4.6549 - val_accuracy: 0.0769\n",
      "Epoch 5/10\n",
      "1326/1326 [==============================] - 27s 21ms/sample - loss: 1.5344 - accuracy: 0.8446 - val_loss: 7.0288 - val_accuracy: 0.0679\n",
      "Epoch 6/10\n",
      "1326/1326 [==============================] - 26s 20ms/sample - loss: 1.3111 - accuracy: 0.8756 - val_loss: 4.7896 - val_accuracy: 0.1878\n",
      "Epoch 7/10\n",
      "1326/1326 [==============================] - 26s 20ms/sample - loss: 1.3765 - accuracy: 0.8801 - val_loss: 2.6984 - val_accuracy: 0.4548\n",
      "Epoch 8/10\n",
      "1326/1326 [==============================] - 29s 22ms/sample - loss: 1.3256 - accuracy: 0.8763 - val_loss: 1.8720 - val_accuracy: 0.7873\n",
      "Epoch 9/10\n",
      "1326/1326 [==============================] - 29s 22ms/sample - loss: 1.2863 - accuracy: 0.8703 - val_loss: 1.5228 - val_accuracy: 0.8100\n",
      "Epoch 10/10\n",
      "1326/1326 [==============================] - 30s 23ms/sample - loss: 1.1842 - accuracy: 0.9065 - val_loss: 1.1345 - val_accuracy: 0.8869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0112 23:55:59.655883 19876 deprecation.py:506] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "pickle_in = open(\"X_HANDWRITTEN.pickle\",\"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "\n",
    "\n",
    "pickle_in = open(\"y_HANDWRITTEN.pickle\",\"rb\")\n",
    "y = pickle.load(pickle_in)\n",
    "\n",
    "X = X/255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "   tf.keras.layers.Conv2D(input_shape=(100,100,1),filters = 32,kernel_size=(3,3),strides = (1,1),data_format='channels_last',activation = 'relu'),\n",
    "   tf.keras.layers.BatchNormalization(),\n",
    "   tf.keras.layers.MaxPool2D(),\n",
    "  \n",
    "   tf.keras.layers.Conv2D(filters = 64,kernel_size=(3,3),data_format = 'channels_last',activation='relu'),\n",
    "   tf.keras.layers.BatchNormalization(),\n",
    "   tf.keras.layers.MaxPool2D(),\n",
    "   \n",
    "   tf.keras.layers.Conv2D(filters = 128,kernel_size=(3,3),strides = (1,1),data_format='channels_last',activation = 'relu'),\n",
    "   tf.keras.layers.BatchNormalization(), \n",
    "   tf.keras.layers.MaxPool2D(),\n",
    "   \n",
    "   tf.keras.layers.Conv2D(filters = 128,kernel_size=(3,3),data_format = 'channels_last',activation = 'relu'),\n",
    "   tf.keras.layers.BatchNormalization(),\n",
    "   tf.keras.layers.MaxPool2D(),\n",
    "  \n",
    "   tf.keras.layers.Conv2D(filters = 256,kernel_size=(3,3),data_format = 'channels_last',activation = 'relu'),\n",
    "   tf.keras.layers.BatchNormalization(),\n",
    "   tf.keras.layers.MaxPool2D(),\n",
    "   \n",
    "   tf.keras.layers.Flatten(data_format = 'channels_last'),\n",
    "    \n",
    "   tf.keras.layers.Dense(1024,activation = 'relu',kernel_regularizer = tf.keras.regularizers.l2(l = 0.09)),\n",
    "   tf.keras.layers.BatchNormalization(),\n",
    "    \n",
    "   tf.keras.layers.Dense(256,activation = 'relu',kernel_regularizer = tf.keras.regularizers.l2(l = 0.09)),\n",
    "   tf.keras.layers.BatchNormalization(),\n",
    "    \n",
    "   tf.keras.layers.Dense(16,activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='Adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X, y, batch_size=16, epochs=10, validation_split=0.25)\n",
    "\n",
    "model.save('CNNHANDWRITTEN.model')\n",
    "model.save_weights('CNNHANDWRITTENWEIGHTS.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(filepath):\n",
    "    IMG_SIZE = 100  # 50 in txt-based\n",
    "    img_array = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n",
    "    img_array=img_array/255.0  # filepathread in the image, convert to grayscale\n",
    "    new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize image to match model's expected sizing\n",
    "    return new_array.reshape(-1,IMG_SIZE, IMG_SIZE,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "model = tf.keras.models.load_model(\"CNNHANDWRITTEN.model\")\n",
    "for i in range(1,104):\n",
    "    prediction = model.predict([prepare(\"Handwritten using motion tracking/0/\" + str(i) + \".jpg\")])\n",
    "    prediction=np.argmax(prediction)\n",
    "    if(prediction!='B'):\n",
    "        count = count + 1\n",
    "        #print(str(i) + \"-prediction here is \" + str(prediction))\n",
    "print(\"count is \" + str(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
