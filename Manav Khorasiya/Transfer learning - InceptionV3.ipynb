{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model \n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras import backend as k \n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "import pickle\n",
    "from keras.applications.vgg16 import VGG16\n",
    "import tensorflow as tf\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.applications.inception_v3 import InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 100, 100\n",
    "\n",
    "base_model = InceptionV3(weights= \"imagenet\",include_top = False,input_shape = (100,100,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_13 (InputLayer)           (None, 100, 100, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_283 (Conv2D)             (None, 49, 49, 32)   864         input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_283 (BatchN (None, 49, 49, 32)   96          conv2d_283[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_283 (Activation)     (None, 49, 49, 32)   0           batch_normalization_283[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_284 (Conv2D)             (None, 47, 47, 32)   9216        activation_283[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_284 (BatchN (None, 47, 47, 32)   96          conv2d_284[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_284 (Activation)     (None, 47, 47, 32)   0           batch_normalization_284[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_285 (Conv2D)             (None, 47, 47, 64)   18432       activation_284[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_285 (BatchN (None, 47, 47, 64)   192         conv2d_285[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_285 (Activation)     (None, 47, 47, 64)   0           batch_normalization_285[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling2D) (None, 23, 23, 64)   0           activation_285[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_286 (Conv2D)             (None, 23, 23, 80)   5120        max_pooling2d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_286 (BatchN (None, 23, 23, 80)   240         conv2d_286[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_286 (Activation)     (None, 23, 23, 80)   0           batch_normalization_286[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_287 (Conv2D)             (None, 21, 21, 192)  138240      activation_286[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_287 (BatchN (None, 21, 21, 192)  576         conv2d_287[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_287 (Activation)     (None, 21, 21, 192)  0           batch_normalization_287[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling2D) (None, 10, 10, 192)  0           activation_287[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_291 (Conv2D)             (None, 10, 10, 64)   12288       max_pooling2d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_291 (BatchN (None, 10, 10, 64)   192         conv2d_291[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_291 (Activation)     (None, 10, 10, 64)   0           batch_normalization_291[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_289 (Conv2D)             (None, 10, 10, 48)   9216        max_pooling2d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_292 (Conv2D)             (None, 10, 10, 96)   55296       activation_291[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_289 (BatchN (None, 10, 10, 48)   144         conv2d_289[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_292 (BatchN (None, 10, 10, 96)   288         conv2d_292[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_289 (Activation)     (None, 10, 10, 48)   0           batch_normalization_289[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_292 (Activation)     (None, 10, 10, 96)   0           batch_normalization_292[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_28 (AveragePo (None, 10, 10, 192)  0           max_pooling2d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_288 (Conv2D)             (None, 10, 10, 64)   12288       max_pooling2d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_290 (Conv2D)             (None, 10, 10, 64)   76800       activation_289[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_293 (Conv2D)             (None, 10, 10, 96)   82944       activation_292[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_294 (Conv2D)             (None, 10, 10, 32)   6144        average_pooling2d_28[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_288 (BatchN (None, 10, 10, 64)   192         conv2d_288[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_290 (BatchN (None, 10, 10, 64)   192         conv2d_290[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_293 (BatchN (None, 10, 10, 96)   288         conv2d_293[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_294 (BatchN (None, 10, 10, 32)   96          conv2d_294[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_288 (Activation)     (None, 10, 10, 64)   0           batch_normalization_288[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_290 (Activation)     (None, 10, 10, 64)   0           batch_normalization_290[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_293 (Activation)     (None, 10, 10, 96)   0           batch_normalization_293[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_294 (Activation)     (None, 10, 10, 32)   0           batch_normalization_294[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 10, 10, 256)  0           activation_288[0][0]             \n",
      "                                                                 activation_290[0][0]             \n",
      "                                                                 activation_293[0][0]             \n",
      "                                                                 activation_294[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_298 (Conv2D)             (None, 10, 10, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_298 (BatchN (None, 10, 10, 64)   192         conv2d_298[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_298 (Activation)     (None, 10, 10, 64)   0           batch_normalization_298[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_296 (Conv2D)             (None, 10, 10, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_299 (Conv2D)             (None, 10, 10, 96)   55296       activation_298[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_296 (BatchN (None, 10, 10, 48)   144         conv2d_296[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_299 (BatchN (None, 10, 10, 96)   288         conv2d_299[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_296 (Activation)     (None, 10, 10, 48)   0           batch_normalization_296[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_299 (Activation)     (None, 10, 10, 96)   0           batch_normalization_299[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_29 (AveragePo (None, 10, 10, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_295 (Conv2D)             (None, 10, 10, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_297 (Conv2D)             (None, 10, 10, 64)   76800       activation_296[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_300 (Conv2D)             (None, 10, 10, 96)   82944       activation_299[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_301 (Conv2D)             (None, 10, 10, 64)   16384       average_pooling2d_29[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_295 (BatchN (None, 10, 10, 64)   192         conv2d_295[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_297 (BatchN (None, 10, 10, 64)   192         conv2d_297[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_300 (BatchN (None, 10, 10, 96)   288         conv2d_300[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_301 (BatchN (None, 10, 10, 64)   192         conv2d_301[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_295 (Activation)     (None, 10, 10, 64)   0           batch_normalization_295[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_297 (Activation)     (None, 10, 10, 64)   0           batch_normalization_297[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_300 (Activation)     (None, 10, 10, 96)   0           batch_normalization_300[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_301 (Activation)     (None, 10, 10, 64)   0           batch_normalization_301[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 10, 10, 288)  0           activation_295[0][0]             \n",
      "                                                                 activation_297[0][0]             \n",
      "                                                                 activation_300[0][0]             \n",
      "                                                                 activation_301[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_305 (Conv2D)             (None, 10, 10, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_305 (BatchN (None, 10, 10, 64)   192         conv2d_305[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_305 (Activation)     (None, 10, 10, 64)   0           batch_normalization_305[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_303 (Conv2D)             (None, 10, 10, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_306 (Conv2D)             (None, 10, 10, 96)   55296       activation_305[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_303 (BatchN (None, 10, 10, 48)   144         conv2d_303[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_306 (BatchN (None, 10, 10, 96)   288         conv2d_306[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_303 (Activation)     (None, 10, 10, 48)   0           batch_normalization_303[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_306 (Activation)     (None, 10, 10, 96)   0           batch_normalization_306[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_30 (AveragePo (None, 10, 10, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_302 (Conv2D)             (None, 10, 10, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_304 (Conv2D)             (None, 10, 10, 64)   76800       activation_303[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_307 (Conv2D)             (None, 10, 10, 96)   82944       activation_306[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_308 (Conv2D)             (None, 10, 10, 64)   18432       average_pooling2d_30[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_302 (BatchN (None, 10, 10, 64)   192         conv2d_302[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_304 (BatchN (None, 10, 10, 64)   192         conv2d_304[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_307 (BatchN (None, 10, 10, 96)   288         conv2d_307[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_308 (BatchN (None, 10, 10, 64)   192         conv2d_308[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_302 (Activation)     (None, 10, 10, 64)   0           batch_normalization_302[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_304 (Activation)     (None, 10, 10, 64)   0           batch_normalization_304[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_307 (Activation)     (None, 10, 10, 96)   0           batch_normalization_307[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_308 (Activation)     (None, 10, 10, 64)   0           batch_normalization_308[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 10, 10, 288)  0           activation_302[0][0]             \n",
      "                                                                 activation_304[0][0]             \n",
      "                                                                 activation_307[0][0]             \n",
      "                                                                 activation_308[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_310 (Conv2D)             (None, 10, 10, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_310 (BatchN (None, 10, 10, 64)   192         conv2d_310[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_310 (Activation)     (None, 10, 10, 64)   0           batch_normalization_310[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_311 (Conv2D)             (None, 10, 10, 96)   55296       activation_310[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_311 (BatchN (None, 10, 10, 96)   288         conv2d_311[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_311 (Activation)     (None, 10, 10, 96)   0           batch_normalization_311[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_309 (Conv2D)             (None, 4, 4, 384)    995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_312 (Conv2D)             (None, 4, 4, 96)     82944       activation_311[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_309 (BatchN (None, 4, 4, 384)    1152        conv2d_309[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_312 (BatchN (None, 4, 4, 96)     288         conv2d_312[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_309 (Activation)     (None, 4, 4, 384)    0           batch_normalization_309[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_312 (Activation)     (None, 4, 4, 96)     0           batch_normalization_312[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling2D) (None, 4, 4, 288)    0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 4, 4, 768)    0           activation_309[0][0]             \n",
      "                                                                 activation_312[0][0]             \n",
      "                                                                 max_pooling2d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_317 (Conv2D)             (None, 4, 4, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_317 (BatchN (None, 4, 4, 128)    384         conv2d_317[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_317 (Activation)     (None, 4, 4, 128)    0           batch_normalization_317[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_318 (Conv2D)             (None, 4, 4, 128)    114688      activation_317[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_318 (BatchN (None, 4, 4, 128)    384         conv2d_318[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_318 (Activation)     (None, 4, 4, 128)    0           batch_normalization_318[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_314 (Conv2D)             (None, 4, 4, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_319 (Conv2D)             (None, 4, 4, 128)    114688      activation_318[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_314 (BatchN (None, 4, 4, 128)    384         conv2d_314[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_319 (BatchN (None, 4, 4, 128)    384         conv2d_319[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_314 (Activation)     (None, 4, 4, 128)    0           batch_normalization_314[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_319 (Activation)     (None, 4, 4, 128)    0           batch_normalization_319[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_315 (Conv2D)             (None, 4, 4, 128)    114688      activation_314[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_320 (Conv2D)             (None, 4, 4, 128)    114688      activation_319[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_315 (BatchN (None, 4, 4, 128)    384         conv2d_315[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_320 (BatchN (None, 4, 4, 128)    384         conv2d_320[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_315 (Activation)     (None, 4, 4, 128)    0           batch_normalization_315[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_320 (Activation)     (None, 4, 4, 128)    0           batch_normalization_320[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_31 (AveragePo (None, 4, 4, 768)    0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_313 (Conv2D)             (None, 4, 4, 192)    147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_316 (Conv2D)             (None, 4, 4, 192)    172032      activation_315[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_321 (Conv2D)             (None, 4, 4, 192)    172032      activation_320[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_322 (Conv2D)             (None, 4, 4, 192)    147456      average_pooling2d_31[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_313 (BatchN (None, 4, 4, 192)    576         conv2d_313[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_316 (BatchN (None, 4, 4, 192)    576         conv2d_316[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_321 (BatchN (None, 4, 4, 192)    576         conv2d_321[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_322 (BatchN (None, 4, 4, 192)    576         conv2d_322[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_313 (Activation)     (None, 4, 4, 192)    0           batch_normalization_313[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_316 (Activation)     (None, 4, 4, 192)    0           batch_normalization_316[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_321 (Activation)     (None, 4, 4, 192)    0           batch_normalization_321[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_322 (Activation)     (None, 4, 4, 192)    0           batch_normalization_322[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 4, 4, 768)    0           activation_313[0][0]             \n",
      "                                                                 activation_316[0][0]             \n",
      "                                                                 activation_321[0][0]             \n",
      "                                                                 activation_322[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_327 (Conv2D)             (None, 4, 4, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_327 (BatchN (None, 4, 4, 160)    480         conv2d_327[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_327 (Activation)     (None, 4, 4, 160)    0           batch_normalization_327[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_328 (Conv2D)             (None, 4, 4, 160)    179200      activation_327[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_328 (BatchN (None, 4, 4, 160)    480         conv2d_328[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_328 (Activation)     (None, 4, 4, 160)    0           batch_normalization_328[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_324 (Conv2D)             (None, 4, 4, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_329 (Conv2D)             (None, 4, 4, 160)    179200      activation_328[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_324 (BatchN (None, 4, 4, 160)    480         conv2d_324[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_329 (BatchN (None, 4, 4, 160)    480         conv2d_329[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_324 (Activation)     (None, 4, 4, 160)    0           batch_normalization_324[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_329 (Activation)     (None, 4, 4, 160)    0           batch_normalization_329[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_325 (Conv2D)             (None, 4, 4, 160)    179200      activation_324[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_330 (Conv2D)             (None, 4, 4, 160)    179200      activation_329[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_325 (BatchN (None, 4, 4, 160)    480         conv2d_325[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_330 (BatchN (None, 4, 4, 160)    480         conv2d_330[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_325 (Activation)     (None, 4, 4, 160)    0           batch_normalization_325[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_330 (Activation)     (None, 4, 4, 160)    0           batch_normalization_330[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_32 (AveragePo (None, 4, 4, 768)    0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_323 (Conv2D)             (None, 4, 4, 192)    147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_326 (Conv2D)             (None, 4, 4, 192)    215040      activation_325[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_331 (Conv2D)             (None, 4, 4, 192)    215040      activation_330[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_332 (Conv2D)             (None, 4, 4, 192)    147456      average_pooling2d_32[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_323 (BatchN (None, 4, 4, 192)    576         conv2d_323[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_326 (BatchN (None, 4, 4, 192)    576         conv2d_326[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_331 (BatchN (None, 4, 4, 192)    576         conv2d_331[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_332 (BatchN (None, 4, 4, 192)    576         conv2d_332[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_323 (Activation)     (None, 4, 4, 192)    0           batch_normalization_323[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_326 (Activation)     (None, 4, 4, 192)    0           batch_normalization_326[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_331 (Activation)     (None, 4, 4, 192)    0           batch_normalization_331[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_332 (Activation)     (None, 4, 4, 192)    0           batch_normalization_332[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 4, 4, 768)    0           activation_323[0][0]             \n",
      "                                                                 activation_326[0][0]             \n",
      "                                                                 activation_331[0][0]             \n",
      "                                                                 activation_332[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_337 (Conv2D)             (None, 4, 4, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_337 (BatchN (None, 4, 4, 160)    480         conv2d_337[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_337 (Activation)     (None, 4, 4, 160)    0           batch_normalization_337[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_338 (Conv2D)             (None, 4, 4, 160)    179200      activation_337[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_338 (BatchN (None, 4, 4, 160)    480         conv2d_338[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_338 (Activation)     (None, 4, 4, 160)    0           batch_normalization_338[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_334 (Conv2D)             (None, 4, 4, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_339 (Conv2D)             (None, 4, 4, 160)    179200      activation_338[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_334 (BatchN (None, 4, 4, 160)    480         conv2d_334[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_339 (BatchN (None, 4, 4, 160)    480         conv2d_339[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_334 (Activation)     (None, 4, 4, 160)    0           batch_normalization_334[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_339 (Activation)     (None, 4, 4, 160)    0           batch_normalization_339[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_335 (Conv2D)             (None, 4, 4, 160)    179200      activation_334[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_340 (Conv2D)             (None, 4, 4, 160)    179200      activation_339[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_335 (BatchN (None, 4, 4, 160)    480         conv2d_335[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_340 (BatchN (None, 4, 4, 160)    480         conv2d_340[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_335 (Activation)     (None, 4, 4, 160)    0           batch_normalization_335[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_340 (Activation)     (None, 4, 4, 160)    0           batch_normalization_340[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_33 (AveragePo (None, 4, 4, 768)    0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_333 (Conv2D)             (None, 4, 4, 192)    147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_336 (Conv2D)             (None, 4, 4, 192)    215040      activation_335[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_341 (Conv2D)             (None, 4, 4, 192)    215040      activation_340[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_342 (Conv2D)             (None, 4, 4, 192)    147456      average_pooling2d_33[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_333 (BatchN (None, 4, 4, 192)    576         conv2d_333[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_336 (BatchN (None, 4, 4, 192)    576         conv2d_336[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_341 (BatchN (None, 4, 4, 192)    576         conv2d_341[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_342 (BatchN (None, 4, 4, 192)    576         conv2d_342[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_333 (Activation)     (None, 4, 4, 192)    0           batch_normalization_333[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_336 (Activation)     (None, 4, 4, 192)    0           batch_normalization_336[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_341 (Activation)     (None, 4, 4, 192)    0           batch_normalization_341[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_342 (Activation)     (None, 4, 4, 192)    0           batch_normalization_342[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 4, 4, 768)    0           activation_333[0][0]             \n",
      "                                                                 activation_336[0][0]             \n",
      "                                                                 activation_341[0][0]             \n",
      "                                                                 activation_342[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_347 (Conv2D)             (None, 4, 4, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_347 (BatchN (None, 4, 4, 192)    576         conv2d_347[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_347 (Activation)     (None, 4, 4, 192)    0           batch_normalization_347[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_348 (Conv2D)             (None, 4, 4, 192)    258048      activation_347[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_348 (BatchN (None, 4, 4, 192)    576         conv2d_348[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_348 (Activation)     (None, 4, 4, 192)    0           batch_normalization_348[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_344 (Conv2D)             (None, 4, 4, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_349 (Conv2D)             (None, 4, 4, 192)    258048      activation_348[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_344 (BatchN (None, 4, 4, 192)    576         conv2d_344[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_349 (BatchN (None, 4, 4, 192)    576         conv2d_349[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_344 (Activation)     (None, 4, 4, 192)    0           batch_normalization_344[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_349 (Activation)     (None, 4, 4, 192)    0           batch_normalization_349[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_345 (Conv2D)             (None, 4, 4, 192)    258048      activation_344[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_350 (Conv2D)             (None, 4, 4, 192)    258048      activation_349[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_345 (BatchN (None, 4, 4, 192)    576         conv2d_345[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_350 (BatchN (None, 4, 4, 192)    576         conv2d_350[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_345 (Activation)     (None, 4, 4, 192)    0           batch_normalization_345[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_350 (Activation)     (None, 4, 4, 192)    0           batch_normalization_350[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_34 (AveragePo (None, 4, 4, 768)    0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_343 (Conv2D)             (None, 4, 4, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_346 (Conv2D)             (None, 4, 4, 192)    258048      activation_345[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_351 (Conv2D)             (None, 4, 4, 192)    258048      activation_350[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_352 (Conv2D)             (None, 4, 4, 192)    147456      average_pooling2d_34[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_343 (BatchN (None, 4, 4, 192)    576         conv2d_343[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_346 (BatchN (None, 4, 4, 192)    576         conv2d_346[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_351 (BatchN (None, 4, 4, 192)    576         conv2d_351[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_352 (BatchN (None, 4, 4, 192)    576         conv2d_352[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_343 (Activation)     (None, 4, 4, 192)    0           batch_normalization_343[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_346 (Activation)     (None, 4, 4, 192)    0           batch_normalization_346[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_351 (Activation)     (None, 4, 4, 192)    0           batch_normalization_351[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_352 (Activation)     (None, 4, 4, 192)    0           batch_normalization_352[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 4, 4, 768)    0           activation_343[0][0]             \n",
      "                                                                 activation_346[0][0]             \n",
      "                                                                 activation_351[0][0]             \n",
      "                                                                 activation_352[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_355 (Conv2D)             (None, 4, 4, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_355 (BatchN (None, 4, 4, 192)    576         conv2d_355[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_355 (Activation)     (None, 4, 4, 192)    0           batch_normalization_355[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_356 (Conv2D)             (None, 4, 4, 192)    258048      activation_355[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_356 (BatchN (None, 4, 4, 192)    576         conv2d_356[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_356 (Activation)     (None, 4, 4, 192)    0           batch_normalization_356[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_353 (Conv2D)             (None, 4, 4, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_357 (Conv2D)             (None, 4, 4, 192)    258048      activation_356[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_353 (BatchN (None, 4, 4, 192)    576         conv2d_353[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_357 (BatchN (None, 4, 4, 192)    576         conv2d_357[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_353 (Activation)     (None, 4, 4, 192)    0           batch_normalization_353[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_357 (Activation)     (None, 4, 4, 192)    0           batch_normalization_357[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_354 (Conv2D)             (None, 1, 1, 320)    552960      activation_353[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_358 (Conv2D)             (None, 1, 1, 192)    331776      activation_357[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_354 (BatchN (None, 1, 1, 320)    960         conv2d_354[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_358 (BatchN (None, 1, 1, 192)    576         conv2d_358[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_354 (Activation)     (None, 1, 1, 320)    0           batch_normalization_354[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_358 (Activation)     (None, 1, 1, 192)    0           batch_normalization_358[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling2D) (None, 1, 1, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 1, 1, 1280)   0           activation_354[0][0]             \n",
      "                                                                 activation_358[0][0]             \n",
      "                                                                 max_pooling2d_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_363 (Conv2D)             (None, 1, 1, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_363 (BatchN (None, 1, 1, 448)    1344        conv2d_363[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_363 (Activation)     (None, 1, 1, 448)    0           batch_normalization_363[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_360 (Conv2D)             (None, 1, 1, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_364 (Conv2D)             (None, 1, 1, 384)    1548288     activation_363[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_360 (BatchN (None, 1, 1, 384)    1152        conv2d_360[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_364 (BatchN (None, 1, 1, 384)    1152        conv2d_364[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_360 (Activation)     (None, 1, 1, 384)    0           batch_normalization_360[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_364 (Activation)     (None, 1, 1, 384)    0           batch_normalization_364[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_361 (Conv2D)             (None, 1, 1, 384)    442368      activation_360[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_362 (Conv2D)             (None, 1, 1, 384)    442368      activation_360[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_365 (Conv2D)             (None, 1, 1, 384)    442368      activation_364[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_366 (Conv2D)             (None, 1, 1, 384)    442368      activation_364[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_35 (AveragePo (None, 1, 1, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_359 (Conv2D)             (None, 1, 1, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_361 (BatchN (None, 1, 1, 384)    1152        conv2d_361[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_362 (BatchN (None, 1, 1, 384)    1152        conv2d_362[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_365 (BatchN (None, 1, 1, 384)    1152        conv2d_365[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_366 (BatchN (None, 1, 1, 384)    1152        conv2d_366[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_367 (Conv2D)             (None, 1, 1, 192)    245760      average_pooling2d_35[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_359 (BatchN (None, 1, 1, 320)    960         conv2d_359[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_361 (Activation)     (None, 1, 1, 384)    0           batch_normalization_361[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_362 (Activation)     (None, 1, 1, 384)    0           batch_normalization_362[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_365 (Activation)     (None, 1, 1, 384)    0           batch_normalization_365[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_366 (Activation)     (None, 1, 1, 384)    0           batch_normalization_366[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_367 (BatchN (None, 1, 1, 192)    576         conv2d_367[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_359 (Activation)     (None, 1, 1, 320)    0           batch_normalization_359[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 1, 1, 768)    0           activation_361[0][0]             \n",
      "                                                                 activation_362[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 1, 1, 768)    0           activation_365[0][0]             \n",
      "                                                                 activation_366[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_367 (Activation)     (None, 1, 1, 192)    0           batch_normalization_367[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 1, 1, 2048)   0           activation_359[0][0]             \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_7[0][0]              \n",
      "                                                                 activation_367[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_372 (Conv2D)             (None, 1, 1, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_372 (BatchN (None, 1, 1, 448)    1344        conv2d_372[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_372 (Activation)     (None, 1, 1, 448)    0           batch_normalization_372[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_369 (Conv2D)             (None, 1, 1, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_373 (Conv2D)             (None, 1, 1, 384)    1548288     activation_372[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_369 (BatchN (None, 1, 1, 384)    1152        conv2d_369[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_373 (BatchN (None, 1, 1, 384)    1152        conv2d_373[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_369 (Activation)     (None, 1, 1, 384)    0           batch_normalization_369[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_373 (Activation)     (None, 1, 1, 384)    0           batch_normalization_373[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_370 (Conv2D)             (None, 1, 1, 384)    442368      activation_369[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_371 (Conv2D)             (None, 1, 1, 384)    442368      activation_369[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_374 (Conv2D)             (None, 1, 1, 384)    442368      activation_373[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_375 (Conv2D)             (None, 1, 1, 384)    442368      activation_373[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_36 (AveragePo (None, 1, 1, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_368 (Conv2D)             (None, 1, 1, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_370 (BatchN (None, 1, 1, 384)    1152        conv2d_370[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_371 (BatchN (None, 1, 1, 384)    1152        conv2d_371[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_374 (BatchN (None, 1, 1, 384)    1152        conv2d_374[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_375 (BatchN (None, 1, 1, 384)    1152        conv2d_375[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_376 (Conv2D)             (None, 1, 1, 192)    393216      average_pooling2d_36[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_368 (BatchN (None, 1, 1, 320)    960         conv2d_368[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_370 (Activation)     (None, 1, 1, 384)    0           batch_normalization_370[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_371 (Activation)     (None, 1, 1, 384)    0           batch_normalization_371[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_374 (Activation)     (None, 1, 1, 384)    0           batch_normalization_374[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_375 (Activation)     (None, 1, 1, 384)    0           batch_normalization_375[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_376 (BatchN (None, 1, 1, 192)    576         conv2d_376[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_368 (Activation)     (None, 1, 1, 320)    0           batch_normalization_368[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 1, 1, 768)    0           activation_370[0][0]             \n",
      "                                                                 activation_371[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 1, 1, 768)    0           activation_374[0][0]             \n",
      "                                                                 activation_375[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_376 (Activation)     (None, 1, 1, 192)    0           batch_normalization_376[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 1, 1, 2048)   0           activation_368[0][0]             \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_8[0][0]              \n",
      "                                                                 activation_376[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 21,768,352\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inception_v3 (Model)         (None, 1, 1, 2048)        21802784  \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 1, 1, 1024)        2098176   \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 1, 1, 256)         262400    \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 24,165,930\n",
      "Trainable params: 24,131,498\n",
      "Non-trainable params: 34,432\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# flat1 = Flatten()(model.outputs)\n",
    "# class1 = Dense(1024, activation='relu')(flat1)\n",
    "# output = Dense(10, activation='softmax')(class1)\n",
    "# # define new model\n",
    "# model = Model(inputs=model.inputs, outputs=output)\n",
    "# # summarize\n",
    "base_model.summary()\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "# # Add the vgg convolutional base model\n",
    "model.add(base_model)\n",
    " \n",
    "# # Add new layers\n",
    "# model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='softmax'))\n",
    " \n",
    "# # Show a summary of the model. Check the number of trainable parameters    \n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"D:/GISA/Newdataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9901 images belonging to 10 classes.\n",
      "Found 2471 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "                                   rescale=1./255,\n",
    "                                   validation_split = 0.2,\n",
    "                                   )\n",
    "\n",
    "'''test_data_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "                                   rescale = 1./255,)'''\n",
    "\n",
    "\n",
    "train_generator = train_data_generator.flow_from_directory(\n",
    "        train_path,\n",
    "        target_size=(100,100),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical',\n",
    "        color_mode = 'rgb',\n",
    "        shuffle = True,\n",
    "        subset = 'training')\n",
    "\n",
    "validation_generator = train_data_generator.flow_from_directory(\n",
    "        train_path,\n",
    "        target_size=(100,100),\n",
    "        batch_size = 32,\n",
    "        class_mode='categorical',\n",
    "        color_mode = 'rgb',\n",
    "        shuffle = True,\n",
    "        subset = 'validation')\n",
    "    \n",
    "#'''creating check-point path to store weights of increased validation accuracy'''\n",
    "        \n",
    "#filepath=\"D:/check_points_for_keras/weights-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
    "#checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=0, save_best_only=True, mode='max')\n",
    "#callbacks_list = [checkpoint]\n",
    "\n",
    "# STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "# STEP_SIZE_VALID=validation_generator.n//validation_generator.batch_size\n",
    "# output = model.fit_generator(train_generator ,\n",
    "#                          steps_per_epoch= STEP_SIZE_TRAIN,\n",
    "#                          epochs= 20,\n",
    "#                          validation_data = validation_generator ,\n",
    "#                          validation_steps = STEP_SIZE_VALID,\n",
    "#                          verbose = 1,\n",
    "#                          callbacks = callbacks_list,\n",
    "#                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inception_v3 (Model)         (None, 1, 1, 2048)        21802784  \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 1, 1, 1024)        2098176   \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 1, 1, 256)         262400    \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 24,165,930\n",
      "Trainable params: 24,131,498\n",
      "Non-trainable params: 34,432\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# model.fit(X, y, batch_size=32, epochs=10, validation_split=0.25)\n",
    "\n",
    "\n",
    "# model.save('transfer-vgg16.model')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_46 to have shape (1,) but got array with shape (10,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-135-5323fe135a73>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidation_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mvalidation_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     epochs = 20)\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[0;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m                                             class_weight=class_weight)\n\u001b[0m\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1209\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1210\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1211\u001b[1;33m             class_weight=class_weight)\n\u001b[0m\u001b[0;32m   1212\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1213\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    787\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m                 exception_prefix='target')\n\u001b[0m\u001b[0;32m    790\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[1;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    136\u001b[0m                             \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m                             str(data_shape))\n\u001b[0m\u001b[0;32m    139\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking target: expected dense_46 to have shape (1,) but got array with shape (10,)"
     ]
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = 8,\n",
    "    validation_data = validation_generator, \n",
    "    validation_steps = 8,\n",
    "    epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
