{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0113 03:38:44.833328 14284 deprecation.py:506] From C:\\Users\\Manav Khorasiya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\ops\\init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0113 03:38:44.837094 14284 deprecation.py:506] From C:\\Users\\Manav Khorasiya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0113 03:38:44.854743 14284 deprecation.py:506] From C:\\Users\\Manav Khorasiya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "W0113 03:38:44.879638 14284 deprecation.py:506] From C:\\Users\\Manav Khorasiya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\ops\\init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(\"CNNHANDWRITTEN.model\" , compile = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(ima):\n",
    "    IMG_SIZE = 100  # 50 in txt-based\n",
    "    img_array = ima*255\n",
    "    img_array=img_array/255.0  # filepathread in the image, convert to grayscale\n",
    "    new_array = cv2.resize(img_array, (IMG_SIZE*3, IMG_SIZE))  # resize image to match model's expected sizing\n",
    "    return new_array.reshape(-1,IMG_SIZE, IMG_SIZE,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha(prediction):\n",
    "    if(prediction==0):\n",
    "        prediction='A'\n",
    "    elif(prediction==1):\n",
    "        prediction='B'\n",
    "    elif(prediction==2):\n",
    "        prediction='C'\n",
    "    elif(prediction==3):\n",
    "        prediction='D'\n",
    "    elif(prediction==4):\n",
    "        prediction='G'\n",
    "    elif(prediction==5):\n",
    "        prediction='L'\n",
    "    elif(prediction==6):\n",
    "        prediction='M'\n",
    "    elif(prediction==7):\n",
    "        prediction='N'\n",
    "    elif(prediction==8):\n",
    "        prediction='O'\n",
    "    elif(prediction==9):\n",
    "        prediction='P'\n",
    "    elif(prediction==10):\n",
    "        prediction='R'\n",
    "    elif(prediction==11):\n",
    "        prediction='S'\n",
    "    elif(prediction==12):\n",
    "        prediction='T'\n",
    "    elif(prediction==13):\n",
    "        prediction='U'\n",
    "    elif(prediction==14):\n",
    "        prediction='V'\n",
    "    elif(prediction==15):\n",
    "        prediction='Z'\n",
    "    else:\n",
    "        prediction='nothing'\n",
    "    return prediction\n",
    "\n",
    "def callback(x):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.namedWindow('image1')\n",
    "cap=cv2.VideoCapture(0)\n",
    "ilowH = 0\n",
    "ihighH = 255\n",
    "ilowS = 0\n",
    "ihighS = 255\n",
    "ilowV = 0\n",
    "ihighV = 255\n",
    "cv2.createTrackbar('lowH1', 'image1', ilowH, 255, callback)\n",
    "cv2.createTrackbar('highH1', 'image1', ihighH, 255, callback)\n",
    "cv2.createTrackbar('lowS1', 'image1', ilowS, 255, callback)\n",
    "cv2.createTrackbar('highS1', 'image1', ihighS, 255, callback)\n",
    "cv2.createTrackbar('lowV1', 'image1', ilowV, 255, callback)\n",
    "cv2.createTrackbar('highV1', 'image1', ihighV, 255, callback)\n",
    "while True:\n",
    "    try:\n",
    "        ret,frame=cap.read()\n",
    "        ilowH1 = cv2.getTrackbarPos('lowH1', 'image1')\n",
    "        ihighH1 = cv2.getTrackbarPos('highH1', 'image1')\n",
    "        ilowS1 = cv2.getTrackbarPos('lowS1', 'image1')\n",
    "        ihighS1 = cv2.getTrackbarPos('highS1', 'image1')\n",
    "        ilowV1 = cv2.getTrackbarPos('lowV1', 'image1')\n",
    "        ihighV1 = cv2.getTrackbarPos('highV1', 'image1')\n",
    "        hsv=cv2.cvtColor(frame,cv2.COLOR_BGR2HSV)\n",
    "        low1=np.array([ilowH1,ilowS1,ilowV1])\n",
    "        high1=np.array([ihighH1,ihighS1,ihighV1])\n",
    "        img_mask1=cv2.inRange(hsv,low1,high1)\n",
    "        output1=cv2.bitwise_and(frame,frame,mask=img_mask1)\n",
    "        new1 = cv2.cvtColor(output1, cv2.COLOR_BGR2GRAY)\n",
    "        dist = cv2.distanceTransform(new1, cv2.DIST_L2, 5)\n",
    "        cv2.normalize(dist, dist, 0, 1.0, cv2.NORM_MINMAX)\n",
    "        M=cv2.moments(dist)\n",
    "        cX = (int(M[\"m10\"] / M[\"m00\"]))\n",
    "        cY = (int(M[\"m01\"] / M[\"m00\"]))\n",
    "        cv2.circle(frame, (cX, cY), 5, (0, 0, 255), -1)\n",
    "        cv2.imshow(\"image1\",frame)\n",
    "        cv2.imshow('dist',dist)\n",
    "        cv2.imshow(\"image\",output1)\n",
    "    except ZeroDivisionError:\n",
    "        pass\n",
    "    if (cv2.waitKey(1) == 13):\n",
    "                break\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n",
    "i=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n"
     ]
    }
   ],
   "source": [
    "cap=cv2.VideoCapture(0)\n",
    "start=time.time()\n",
    "black=np.zeros((output1.shape[0],output1.shape[1]))\n",
    "j=1\n",
    "while True:\n",
    "    try:\n",
    "        ret,frame=cap.read()\n",
    "        hsv=cv2.cvtColor(frame,cv2.COLOR_BGR2HSV)\n",
    "        low1=np.array([ilowH1,ilowS1,ilowV1])\n",
    "        high1=np.array([ihighH1,ihighS1,ihighV1])\n",
    "        img_mask1=cv2.inRange(hsv,low1,high1)\n",
    "        output1=cv2.bitwise_and(frame,frame,mask=img_mask1)\n",
    "        new1 = cv2.cvtColor(output1, cv2.COLOR_BGR2GRAY)\n",
    "        dist = cv2.distanceTransform(new1, cv2.DIST_L2, 5)\n",
    "        cv2.normalize(dist, dist, 0, 1.0, cv2.NORM_MINMAX)\n",
    "        M=cv2.moments(dist)\n",
    "        cX = (int(M[\"m10\"] / M[\"m00\"]))\n",
    "        cY = (int(M[\"m01\"] / M[\"m00\"]))\n",
    "        cv2.circle(frame, (cX, cY), 5, (255, 252, 255), -1)\n",
    "        cv2.circle(black, (cX, cY), 5, (255, 255, 255), -1)\n",
    "#         if(j==1) :\n",
    "#             cv2.putText(black,\"start\",(cX,cY),cv2.FONT_HERSHEY_SIMPLEX,1.0,(255,0,0),lineType=cv2.LINE_AA)\n",
    "#         else :\n",
    "        if(j!=1):\n",
    "            cv2.line(black,(sX,sY),(cX,cY),(255,255,255),5)\n",
    "        cv2.imshow(\"image1\",frame)\n",
    "        cv2.imshow(\"image\",output1)\n",
    "        cv2.imshow(\"path\",black)\n",
    "        j=j+1\n",
    "        sX=cX\n",
    "        sY=cY\n",
    "        end=time.time()\n",
    "        diff=end-start\n",
    "        if (diff>7):\n",
    "            black=cv2.flip(black,1)\n",
    "            cv2.imwrite(\"Handwritten using motion tracking/\"+str(i)+\".jpg\",black)\n",
    "            img = cv2.imread(\"Handwritten using motion tracking/\"+str(i)+\".jpg\")\n",
    "            prediction = model.predict([prepare(new1)])\n",
    "            prediction=np.argmax(prediction)\n",
    "            x1=alpha(prediction)\n",
    "            #x1=1\n",
    "            cv2.putText(img,str(x1),(60,60),cv2.FONT_HERSHEY_SIMPLEX,3.0,(0,255,255),lineType=cv2.LINE_AA)\n",
    "            cv2.imshow('new',img)\n",
    "            black=np.zeros((output1.shape[0],output1.shape[1]))\n",
    "            i=i+1\n",
    "            start=time.time()\n",
    "            print(\"hi\")\n",
    "    except ZeroDivisionError:\n",
    "        pass\n",
    "    if (cv2.waitKey(1) == 13):\n",
    "                break\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
