{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "model = tf.keras.models.load_model(\"CNNDISTANCE2.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(ima):\n",
    "    IMG_SIZE = 100# 50 in txt-based\n",
    "    img_array=ima*255\n",
    "    #img_array = cv2.cvtColor(ima,cv2.COLOR_BGR2GRAY)\n",
    "    img_array=img_array/255.0  # filepathread in the image, convert to grayscale\n",
    "    new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize image to match model's expected sizing\n",
    "    return new_array.reshape(-1,IMG_SIZE, IMG_SIZE,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paa_skin(image,image1):  \n",
    "    rw=300\n",
    "    rh=300\n",
    "    cx=100\n",
    "    cy=100\n",
    "    hsv=cv2.cvtColor(image,cv2.COLOR_BGR2HSV)\n",
    "    ycbcr=cv2.cvtColor(image, cv2.COLOR_BGR2YCrCb)\n",
    "    b,g,r=cv2.split(image)\n",
    "    y,cr,cb=cv2.split(ycbcr)\n",
    "    h,s,v=cv2.split(hsv)\n",
    "    s=s/(h+s+v)\n",
    "    paa=((0<=h)*(h<=50)*(0.23<s)*(s<0.68)*(r>95)*(g>40)*(b>20)*(r>g)*(r>b)*(abs(r-g)>15))+((r>95)*(g>40)*(b>20)*(r>g)*(r>b)*(abs(r-g)>15)*(cr>135)*(cb>85)*(y>80)*(cr<=(1.5862*cb+20))*(cr>=(0.3448*cb+76.2069))*(cr>=(-4.5652*cb+234.5652))*(cr<=-1.15*cb+301.75)*(cr<=-2.2857*cb+432.85))\n",
    "    b=b*paa\n",
    "    g=g*paa\n",
    "    r=r*paa\n",
    "    new=cv2.merge((b,g,r))\n",
    "    paa=paa*255\n",
    "    new1=cv2.merge((paa,paa,paa))\n",
    "    cv2.imwrite(\"/home/paa/55.jpeg\",new1)\n",
    "    new1=cv2.imread(\"/home/paa/55.jpeg\")\n",
    "    new1 = cv2.cvtColor(new1, cv2.COLOR_BGR2GRAY)\n",
    "    dist = cv2.distanceTransform(new1, cv2.DIST_L2, 5)\n",
    "    cv2.normalize(dist, dist, 0, 1.0, cv2.NORM_MINMAX)\n",
    "    return image1,dist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paa/anaconda3/envs/opencv-env/lib/python2.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in divide\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "cap=cv2.VideoCapture(0)\n",
    "cx=100\n",
    "cy=100\n",
    "rw=300\n",
    "rh=300\n",
    "while True:\n",
    "    ret, image=cap.read()\n",
    "    pre=image[cx:rw,cy:rh]\n",
    "    image1,dist=paa_skin(pre,image)\n",
    "    prediction = model.predict([prepare(dist)])\n",
    "    prediction=np.argmax(prediction)\n",
    "    x1=prediction\n",
    "    try:\n",
    "        cv2.putText(image,str(x1),(60,60),cv2.FONT_HERSHEY_SIMPLEX,3.0,(255,0,0),lineType=cv2.LINE_AA)\n",
    "    except:\n",
    "        print(\"Variable x1 is not empty\")\n",
    "    cv2.rectangle(image,(cx,cy),(cx+rw,cy+rh),(0,0,0),5)\n",
    "    cv2.imshow('dist',dist)\n",
    "    cv2.imshow('image1',image1)\n",
    "    keypress = cv2.waitKey(1) & 0xFF\n",
    "    if keypress == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
